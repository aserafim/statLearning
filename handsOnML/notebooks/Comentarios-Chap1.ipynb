{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AenJlzt8jSQu"
   },
   "source": [
    "<h2> Notas </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HnmhTD_9jZSs"
   },
   "source": [
    "<h4>Alguns termos</h4>\n",
    "\n",
    "<b>Training Set: </b> É o conjunto de dados utilizado para treinar o modelo.<br><br>\n",
    "\n",
    "<b>Training Instance: </b> Cada exemplo da base de treino, cada observação da base.<br><br>\n",
    "\n",
    "<b>Accuracy: </b> É a medida utilizada para avaliar o poder de aprendizado da máquina. Se tratando de uma ML para classificação, a acurácia pode ser medida como a capacidade que a máquina terá para classificar os dados após seu treinamento.<br><br>\n",
    "\n",
    "<b>Redução de dimensionalidade: </b> uma atividade comum aos modelos não supervisionados, que consiste em reduzir a dimensão do conjunto de dados original, sem que ele perca muito de sua informação. Uma maneira simples de fazer isso é agrupando <i>features</i> que possuem alguma correlação. Ainda <strong> sempre é interessante realizar uma redução de dimensionalidade antes de executar o modelo</strong>, pois desta forma você estará reduzindo o esforço computacional da máquina e performando melhor seu algoritmo.<br><br>\n",
    "\n",
    "<b>Overfitting: </b>O <i>overfitting</i> ocorre quando nosso modelo \"decora\" os dados de teste, provocando o sobreajuste. Desta forma nosso modelo não será capaz de generalizar o aprendizado para novas instâncias de dados. Podemos dizer ainda que um modelo overfitted é um modelo muito complexo.<br><br>\n",
    "\n",
    "<b>Underfitting: </b>O <i>underfitting</i> é justamente o oposto do anterior e ocorre quando nosso modelo não consegue aprender nada, sequer do conjunto de treino. Análogamente ao caso anterior, um modelo underfitted é dito um modelo muito simples.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TkElRlxQj2eH"
   },
   "source": [
    "<h4>Workflow da criação de um modelo</h4><br>\n",
    "\n",
    "<p>\n",
    "<li><b>Estudar os dados</b>: Um passo importante para entender o desafio proposto e de que forma lidar com ele. Além disso, conhecer os dados é importante para decidir quais variáveis manter(ou descartar), como tratar nulidades e missings, etc.</li><br>\n",
    "\n",
    "<li><b>Escolher o modelo</b>: Uma vez conhecido o problema é necessário decidir qual modelo será utilizado. Isso depende muito do tipo de problema(classificação ou agrupamento), quantidade de dados disponivel e, porque não, tempo e recursos disponíveis para execução do projeto.</li><br>\n",
    "\n",
    "<li><b>Treinar o modelo</b>: O próximo passo é treinar o modelo. Selecionamos um conjunto de dados para o treinamento do algoritmo e, partir desses dados, a máquina será capaz de determinar quais são os parâmetros do modelo.</li><br>\n",
    "\n",
    "\n",
    "<li><b>Inferência</b>: Após treinada a rede, passamos a ela novos casos(desconhecidos) afim de verificar se a classificação dada será correta.</li><br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GvQprVSYjJq8"
   },
   "source": [
    "<h4>Principais Desafios</h4>\n",
    "<p>Quando estamos pensando em utilizar um algoritmo de ML como solução, dois problemas principais podem surgir: um conjunto ruim de dados ou um algoritmo ruim.</p><br>\n",
    "    \n",
    "<b>Quantidade de dados</b><p>Diferente de nós, seres humanos, que podemos aprender facilmente por associação (basta mostrar a uma criança o que é uma maçã e repetir o processo algumas vezes para que ela aprenda, por exemplo), as máquinas mesmo para problemas simples, precisam de muitos exemplos, ou seja, dados de treino. Quando pensamos em problemas mais complexos, a quantidade de dados e tempo de treino tende a escalar.</p>\n",
    "<p>Diversos artigos defendem a ideia de que em muitos casos a quantidade e qualidade dos dados é mais importante do que o algoritmo utilizado. No entanto, no mundo real, nem sempre dispomos de uma boa quantidade de dados bem tratados, sendo assim, faz-se necessário pensar bem na escolha do algoritmo.</p>\n",
    "<p><strong>Veja:</strong> Michele Banko/Eric Brill, Peter Norvig: \"The Unreasonable Effectiveness of Data\"</p><br>\n",
    "\n",
    "<b>Dados não representativos</b><p>Um problema comum acontece quando os nossos dados não são representativos da população de estudo. Por exemplo, quando temos dados desbalanceados. Considere um conjunto de dados de clientes, em que queremos saber se a partir do sexo do cliente ele estará mais propenso a comprar um determinado produto ou não. Se nossos dados contiverem 90% de homens e 10% de mulheres, teremos um conjunto de dados dito desbalanceado, uma vez que a maioria dos dados é referente a homens. Sendo assim, nossa máquina não irá aprender o suficiente acerca das mulheres e quando receber instâncias desse tipo, tenderá a classificar mal.</p> <p><b>Note:</b> Grande parte do trabalho de um cientista de dados é gasto na higienização dos dados.</p><br>\n",
    "\n",
    "<b>Dados ruins</b><p>É normal que nossa base de dados crua contenha muitos outiliers ou missing values. Essas ocorrências tendem a resultar em problemas no aprendizado da máquina e, portanto, precisam ser tratadas antes do treinamento.</p><br>\n",
    "\n",
    "<b>Features irrelevantes</b><p>Quando analisamos os dados de trabalho, precisamos identificar as melhores features que se aplicam ao modelo, combinar algumas delas, afim de gerar novas features mais representativas e, em alguns casos, utilizar cruzamento de bases (obter novos dados), afim de criar features novas (a saber, <i>feature selection, feature extraction, creatin new features,</i>).</p><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Troubleshooting</h4>\n",
    "<p>Como solucionar alguns problemas encontrados na criação de um modelo? Vejamos alguns exemplos.</p><br>\n",
    "\n",
    "<p><b>Underfitting -</b> As principais opções para contornar problemas desse tipo são:\n",
    "    <li>Selecionar um modelos mais robusto com mais parâmetros.</li>\n",
    "    <li>Alimentar melhor as features do algoritmo de aprendizado (feature engineering)</li>\n",
    "        <li>Reduzir as restrições do modelo, ou seja, trabalhar em cima dos hiperparâmetros</li>\n",
    "    <br>\n",
    "<p><b>Overfitting - </b>Algumas técnicas que podem ser utilizadas para contornar os problemas de overfitting incluem:\n",
    "    <li>Simplificar o modelo, selecionando um modelo com menos parâmetros.</li>\n",
    "    <li>Alimentar o conjunto de treinamento com mais instâncias.</li>\n",
    "    <li>Corrigir os erros nos dados de treino (outliers, missings).</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNlreW+BZZS7e6+ioQtgJ/E",
   "name": "Comentarios-Chap1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
