{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WPul3KvVX881"
   },
   "source": [
    "<h2>Exercícios comentados do Capítulo 1</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "omp9JUi4UgPz"
   },
   "source": [
    "<p><b> Exercicio 1 </b> - How would you define Machine Learning?  </p>\n",
    "\n",
    "<p><b>R:</b> De acordo com o autor, podemos definir ML como a ciência/arte de programar computadores para aprender com base em dados e não em regras de código explícitas. </p><br>\n",
    "\n",
    "\n",
    "<p><b> Exercicio 2 </b> - Can you name four types of problems where it shines?</p>\n",
    "<p><b>R:</b> Podemos citar problemas de classificação, clusterização, que se subdividem em problemas reais, como a tarefa de agrupar clientes com base no seu perfil de comportamento ou mesmo o problema de classificar os clientes entre bons ou maus pagadores. </p><br>\n",
    "\n",
    "\n",
    "<p><b> Exercicio 3 </b> - What is a labeled training set? </p>\n",
    "<p><b>R:</b> Um conjunto de dados descritivos de algum objeto, cuja classe do objeto é conhecida. Por exemplo, podemos ter um conjunto de dados que descrevem gatos e cachorros, a partir de suas características. Para cada instância deste conjunto (cada vetor de dados), teremos as características do objeto (do animal) e um rótulo indicando se pertence ao grupo de gatos ou cachorros. </p><br>\n",
    "\n",
    "<p><b> Exercicio 4 </b> - What are the two most common supervised tasks? </p>\n",
    "<p><b>R:</b> Os problemas mais comumente solucionáveis através de modelos supervisionados são o de classificação ilustrado acima (classificar entre gatos e cachorros) e o problema de prever um valor de probabilidade. Voltando ao exemplo anterior, poderíamos querer saber qual a probabilidade de um conjunto de dados descritivos pertencer ao grupo de gatos ou de cachorros. </p><br>\n",
    "\n",
    "<p><b> Exercicio 5 </b> - Can you name four common unsupervised tasks? </p>\n",
    "<p><b>R:</b> Agrupamento - identificar padrões em um conjunto de dados e agrupá-los de acordo.<p>Visualização - apresentar os padrões encontrados nos dados de maneira mais amigável, mais fácil de se visualizar.</p><p> Redução de dimensionalidade - Reduz a dimensão dos dados sem que eles percam muito de sua informação.</p><p> </p><p>Associação de regras de aprendizado - Descobrir quais features se relacionam com outras. </p><br>\n",
    "\n",
    "<p><b> Exercicio 6 </b> - What type of Machine Learning algorithm would you use to allow a robot to walk in various unknown terrains? </p>\n",
    "<p><b>R:</b> Para problemas como esse o ideal seria utilizarmos algoritmos de aprendizado por reforço, uma vez que através da tentativa e erro o robô ganhará experiência e aprenderá como andar nos mais diversos tipos de terreno em que se encontrar. </p><br>\n",
    "\n",
    "<p><b> Exercicio 7 </b> - What type of algorithm would you use to segment your customers into multiple groups? </p>\n",
    "<p><b>R:</b> Segmentação ou agrupamento é um problema típicamente resolvível através do uso de modelos náo supervisionados, como o KNN. </p><br>\n",
    "\n",
    "<p><b> Exercicio 8 </b> - Would you frame the problem of spam detection as a supervised learning problem or an unsupervised learning problem? </p>\n",
    "<p><b>R:</b> Esse é um problema clássico de aprendizado supervisionado, uma vez que passaremos para o algoritmo um conjunto de dados já rotulado, afim de que ele aprenda o que é SPAM e o que não é.</p><br>\n",
    "\n",
    "<p><b> Exercicio 9 </b> - What is an online learning system? </p>\n",
    "<p><b>R:</b> Um sistema de aprendizado online ou incremental é um sistema capaz de aprender a partir de novas instâncias de dados. Ou seja, uma vez treinada, a máquina pode receber um novo conjunto de dados de treinamento, sem perder o \"conhecimento aprendido\" anteriormente. </p><br>\n",
    "\n",
    "<p><b> Exercicio 10 </b> - What is out-of-core learning? </p>\n",
    "<p><b>R:</b> Todo sistema é desenvolvido pensando nos recursos limitados da máquina aonde ele irá ser executado. Um dos maiores limitantes é a memória disponível. Considerando um conjunto de dados muito grande que não pode ser armazenado na memória disponível pela máquina. Um algoritmo <i>out-of-core</i> é um sistema que divide o conjunto de dados original em partes menores, alocáveis na memória da máquina e aprende incrementalmente a partir destes <i>clusters</i> de dados. </p><br>\n",
    "\n",
    "<p><b> Exercicio 11 </b> - What type of learning algorithm relies on a similarity measure to make predictions? </p>\n",
    "<p><b>R:</b> Os algoritmos que utilizam uma medida de similaridade são os conhecidos como <i>instance-based learning algorithms</i>. Para cada nova instância apresentada ao algoritmo, ele tentará encontrar um elemento que seja mais similiar ao novo elemento apresentado, para assim classificá-lo.\n",
    "\n",
    "<p>Por outro lado, o aprendizado por modelo utiliza-se de uma função de custo ou uma função de utilidade, que visa medir quão mal(ou bem) o modelo está classificando. A título de exeplo podemos pensar no classificador MLP utilizando uma função de erro para calcular a diferença entre o target e a previsão feita pela rede.</p> </p><br>\n",
    "\n",
    "<p><b> Exercicio 12 </b> - What is the difference between a model parameter and a learning algorithm’s hyperparameter? </p>\n",
    "<p><b>R:</b> Os hiperparâmetros são os valores de configuração inicial do nosso algoritmo. Por exemplo, se pensarmos numa rede neural simples, antes de realizar o nosso treinamento precisamos decidir quantos neurônios terá nossa rede, quantas camadas ocultas, qual a taxa de aprendizado, etc. Por outro lado, os pesos que a rede encontrará após o treinamento são os parâmetros da rede, ou seja, os parâmetros são os valores de ajuste utilizados(obtidos) pela rede.</p><br>\n",
    "\n",
    "<p><b> Exercicio 13 </b> - What do model-based learning algorithms search for? What is the most common strategy they use to succeed? How do they make predictions? </p>\n",
    "<p><b>R:</b> Algoritmos model-based procuram pelos parâmetros que melhor descrevem a função que delimita a região de classificação dos dados. Define-se uma métrica para garantir que o aprendizado da rede seja o melhor possível, esta métria pode ser baseada no quão bem o algoritmo classifica, como também em quão mal ele o faz.\n",
    "<p>\n",
    "Após treinado o algoritmo, podemos passar novas instâncias dos dados para ele. Uma vez coletados os dados, ele os aplicará no modelo afim de descobrir em qual região do gráfico (com relação a região de classificação do modelo) se encontram os novos dados.\n",
    "</p> </p><br>\n",
    "\n",
    "<p><b> Exercicio 14 </b> - Can you name four of the main challenges in Machine Learning? </p>\n",
    "<p><b>R:</b> Poucos dados, dados pobres(ou poluídos), dados não representativos, features irrelevantes(precisamos ter dados com variáveis \"poderosas\" que possibilitem que a máquina aprenda bem acerca deles). </p><br>\n",
    "\n",
    "<p><b> Exercicio 15 </b> - If your model performs great on the training data but generalizes poorly to new instances, what is happening? Can you name three possible solutions? </p>\n",
    "<p><b>R:</b> Isso é um clássico problema de overfitting, quando o modelo \"decora\" os dados de treino e não consegue classificar bem para novas instâncias. Algumas soluções aplicáveis são: selecionar um modelo diferente, que considere menos parâmetros, uma vez que esse porblema pode ser decorrente de alguns atributos ruins, um novo modelo que considere menos atributos pode ser mais performático. Outra opção é considerar um data set maior e, por fim, pode-se reduzir os gaps do data-set, higienizando os dados. </p><br>\n",
    "\n",
    "<p><b> Exercicio 16 </b> - What is a test set and why would you want to use it? </p>\n",
    "<p><b>R:</b> Afim de validarmos se nosso modelo está generalizando bem, o ideal é utilizarmos dois conjuntos distintos, um para o treinamento, <i>training set</i> e outro para execução de testes, <i>training set</i> </p><br>\n",
    "\n",
    "<p><b> Exercicio 17 </b> - What is the purpose of a validation set? </p>\n",
    "<p><b>R:</b> Após treinado o modelo e executar testes num conjunto de dados distintos do conjunto utilizado no treinamento, podemos validar se o modelo está generalizando bem ou se está apresentando um overfitting do conjunto de treinamento. Utilizando essa estratégia evitamos overfitting.</p><br>\n",
    "\n",
    "<p><b> Exercicio 18 </b> - What can go wrong if you tune hyperparameters using the test set? </p>\n",
    "<p><b>R:</b> Corremos o risco de otimizar o modelo para esse conjunto de teste específico. Sendo assim, nosso modelo não irá generalizar bem, não irá apresentar bons resultados para um conjunto de dados distinto. </p><br>\n",
    "\n",
    "<p><b> Exercicio 19 </b> - What is cross-validation and why would you prefer it to a validation set? </p>\n",
    "<p><b>R:</b> Uma técnica onde se cria subconjuntos a partir do conjunto de treino - digamos que 5 subconjuntos. Então o modelo é treinado utilizando 4 destes conjuntos e é testado no conjunto que sobrou. Todos esses conjuntos são criados aleatóriamente e com reposição. A vantagem de utilizar essa técnica ao invés do conjunto de validação é o fato de que não será necessário criar mais um conjunto de a partir do conjunto original. Em projetos onde o conjunto de dados não é muito extenso, essa pode ser uma ótima opção. </p><br>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOdbvc5tog+9mvA3iUdsMxC",
   "name": "Exorcicios-Chap1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
